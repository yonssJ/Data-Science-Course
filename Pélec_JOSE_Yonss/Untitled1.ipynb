{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ddfd21-30ee-4ccf-912d-e15744680e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_valuess=pd.DataFrame()\n",
    "shap_valuess1=pd.DataFrame()#\n",
    "\n",
    "for model_idx in Classifiers_best: #param_best:\n",
    "    model  = param_best[model_idx]\n",
    "    if model_idx !='DummyClassifier':\n",
    "        print(model_idx)\n",
    "        my_model = Classifiers_best[model_idx].fit(X_train,Y_train)\n",
    "        explainer = shap.TreeExplainer(my_model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        shap_valuess[model_idx]=shap_values\n",
    "        shap_valuess1[model_idx]=shap_values[1].ravel()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178e0cb-2920-403e-a2a0-fb7abbfda94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeliser_data_unbalanced(nsplits,X_train, Y_train,X_test,Y_test,Classifiers):\n",
    "\n",
    "  best_params= {}\n",
    "  cout_append= []\n",
    "  frames_test= [] \n",
    "  score_value= []\n",
    "  scores = []\n",
    "  column_Classifiers=[]\n",
    "  save_model = pd.DataFrame()\n",
    "  threshold=[0,0.001,0.002, 0.003,0.004,0.005,0.006,0.007,0.008,0.009,0.01,0.011, \n",
    "             0.012, 0.013,0.014,0.015, 0.02,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "  frames_FI=pd.DataFrame()\n",
    "  frames_FI1=pd.DataFrame()\n",
    "  for model_idx in Classifiers:\n",
    "    column_Classifiers.append(model_idx)\n",
    "    print(model_idx)\n",
    "    model  = Classifiers[model_idx]\n",
    "    my_model=model.fit(X_train, Y_train)\n",
    "    #   \n",
    "    Findex      = str('C.Pred')      +'_' + model_idx\n",
    "    Findex_proba= str('C.Pred_proba')+'_' + model_idx  \n",
    "    y_predite   = pd.DataFrame(my_model.predict(X_test) ,index=Y_test.index,columns=[Findex]) \n",
    "    y_pred_proba= pd.DataFrame(my_model.predict_proba(X_test)[:,1] ,index=Y_test.index,columns=[Findex_proba])\n",
    "    \n",
    "    if model_idx == 'DummyClassifier':\n",
    "      y_pred      = pd.concat([Y_test,y_predite, y_pred_proba],axis=1)\n",
    "    else:\n",
    "      y_pred      = pd.concat([y_predite, y_pred_proba],axis=1)\n",
    "    frames_test.append(y_pred)\n",
    "\n",
    "    # Check Feature Importance\n",
    "    if model_idx != 'DummyClassifier':\n",
    "      explainer  = shap.TreeExplainer(my_model)\n",
    "      shap_values= explainer.shap_values(X_test)\n",
    "      frames_FI[model_idx]=shap_values\n",
    "      frames_FI1[model_idx]=shap_values[1].ravel()\n",
    "\n",
    "    # Function cout\n",
    "    acu_scores= accuracy_score(Y_test, y_predite)\n",
    "    auc_scores= roc_auc_score(Y_test, y_pred_proba) \n",
    "    data      = {'Model':model_idx,'ACCURACY': [acu_scores], 'ROC_AUC':[auc_scores]}  \n",
    "    scores.append(pd.DataFrame(data) )\n",
    "\n",
    "    cost_function = []\n",
    "    cost_ind = []\n",
    "    for thre in threshold:\n",
    "      Ypred=(y_pred_proba>thre)\n",
    "      Ypred = np.array(Ypred > 0) * 1\n",
    "      cost_function.append(custom_metric(Y_test, Ypred))\n",
    "      cost_ind.append(thre)\n",
    "      newname=str('cout') + '_'+ str(model_idx)\n",
    "    cout    = pd.DataFrame(cost_function,columns=[newname]) \n",
    "    cout_append.append(cout)\n",
    "    if model_idx == 'DummyClassifier':\n",
    "      idx_cout= pd.DataFrame(cost_ind,columns=['Threshold']) \n",
    "\n",
    "    df_pred = pd.concat(frames_test, axis=1)\n",
    "    \n",
    "    cost    = pd.concat(cout_append,axis=1)\n",
    "    cost['Threshold']= idx_cout['Threshold']\n",
    "    cost      = cost.set_index('Threshold')\n",
    "    df_results= pd.concat(scores,axis=0)\n",
    "    df_results= df_results.set_index('Model')\n",
    "    save_model[model_idx]=[my_model]\n",
    "\n",
    "  return df_pred, frames_FI, frames_FI1, df_results, cost, save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9afbd-f867-4083-b37c-e358f8e01878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Notons un fort déséquilibre entre la précision trouvée pour la Target 0 (0.92) et la Target 1 (0). Pour rappel, l'échantillon de travail n'est pas équilibré, avec 92% des individus classés en modalité 0 et 8% en modalité 1, à savoir en défaut de paiement de crédit..\n",
    "\n",
    "Il est donc intéressant de travailler cet Oversampling (ou suréchantillonnage en français) en ajustant la distribution de classe de manière à avoir une répartition plus égalitaire.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
